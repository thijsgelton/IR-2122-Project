{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mJZrosDbYj8H",
    "outputId": "7c26eca8-c80c-435b-c986-4fa311043d1a"
   },
   "outputs": [],
   "source": [
    "!pip3 install scikit-surprise\n",
    "!pip install papermill\n",
    "!pip install recommenders[examples,gpu]\n",
    "!pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FE7tuuj83x3h"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from recommenders.datasets.split_utils import min_rating_filter_pandas\n",
    "import surprise\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import KNNBaseline\n",
    "from recommenders.evaluation.python_evaluation import (rmse, mae, rsquared, exp_var, map_at_k, ndcg_at_k, precision_at_k, \n",
    "                                                     recall_at_k, get_top_k_items)\n",
    "from recommenders.models.surprise.surprise_utils import predict, compute_ranking_predictions\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.utils.timer import Timer\n",
    "from surprise.model_selection import train_test_split\n",
    "# from surprise.accuracy import rmse\n",
    "from surprise import accuracy\n",
    "from recommenders.utils.python_utils import binarize\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from prettytable import PrettyTable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZjswRouqBApe"
   },
   "outputs": [],
   "source": [
    "my_seed = 0\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "QqNNb7TG5QBk",
    "outputId": "75d09e58-906b-44d7-8a44-70136b33178c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A3HX4X3TIABWOV</td>\n",
       "      <td>B000KPIHQ4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A3HX4X3TIABWOV</td>\n",
       "      <td>B000V0IBDM</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A3QY3THQ42WSCQ</td>\n",
       "      <td>B000YFSR5G</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AGZ5OOZVDO194</td>\n",
       "      <td>B000YFSR5G</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A3GJ3DJU1RXOHN</td>\n",
       "      <td>B000YFSR4W</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            userID      itemID  rating\n",
       "10  A3HX4X3TIABWOV  B000KPIHQ4       2\n",
       "17  A3HX4X3TIABWOV  B000V0IBDM       2\n",
       "24  A3QY3THQ42WSCQ  B000YFSR5G       1\n",
       "25   AGZ5OOZVDO194  B000YFSR5G       5\n",
       "26  A3GJ3DJU1RXOHN  B000YFSR4W       4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[[\"userID\", \"itemID\", \"rating\"]] = pd.read_json(\"../data/AMAZON_FASHION_5.71.268.json\")[[\"userID\", \"itemID\", \"rating\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y_neXzyt5YUI",
    "outputId": "5de66971-47d7-4bc5-c679-7b802d53d70e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3010, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TIHwPp5pBC8z",
    "outputId": "379ba44a-cfb6-454e-fdfd-7ca5ecf09e93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2072\n",
       "4     443\n",
       "3     310\n",
       "1     109\n",
       "2      76\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5zBE3SVmcJSp"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHgznuZecVLu",
    "outputId": "6862fa25-c21c-43d0-967b-61b230c925ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of               userID      itemID  rating\n",
       "10    A3HX4X3TIABWOV  B000KPIHQ4       2\n",
       "17    A3HX4X3TIABWOV  B000V0IBDM       2\n",
       "24    A3QY3THQ42WSCQ  B000YFSR5G       1\n",
       "25     AGZ5OOZVDO194  B000YFSR5G       5\n",
       "26    A3GJ3DJU1RXOHN  B000YFSR4W       4\n",
       "...              ...         ...     ...\n",
       "3171  A2077NII5H62R2  B005AGO4LU       5\n",
       "3172  A2IBS6PIPAGAB5  B005AGO4LU       5\n",
       "3173  A1GTC5EVSJNCQ8  B005AGO4LU       5\n",
       "3174  A311XHHLM12MUT  B005AGO4LU       5\n",
       "3175  A135SGOQMVWABQ  B005AGO4LU       5\n",
       "\n",
       "[3010 rows x 3 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_L62KtsI5P7V",
    "outputId": "8eb2a8e9-1370-4bd8-cdd0-3e4b6af9d71f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 3010 ratings from 388 users on 27 products (sparsity: 71.268%)\n"
     ]
    }
   ],
   "source": [
    "usercount = df[['userID']].groupby('userID', as_index = False).size()\n",
    "itemcount = df[['itemID']].groupby('itemID', as_index = False).size()\n",
    "\n",
    "density = 1. * df.shape[0] / (usercount.shape[0] * itemcount.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d ratings from %d users on %d products (sparsity: %.3f%%)\" % \n",
    "      (df.shape[0], usercount.shape[0], itemcount.shape[0], (1 - density) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uR0-b0Ak8-MW",
    "outputId": "aa906de1-28a9-4739-d2a7-1cfdbb8f1f29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2072\n",
       "4     443\n",
       "3     310\n",
       "1     109\n",
       "2      76\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k1GYfCZIzui2",
    "outputId": "5f70ebb4-54f2-4739-c266-feb1e7ab9460"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3010, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSoonoAOYu87"
   },
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqoLU3tzwUEB"
   },
   "outputs": [],
   "source": [
    "def GetTopN(predictions, n, minimumRating, criterion):\n",
    "    topN = defaultdict(list)\n",
    "    \n",
    "    for index, row in predictions.iterrows():\n",
    "        if (row[criterion] >= minimumRating):\n",
    "            topN[(row.uid)].append(((row.iid), row[criterion]))\n",
    "\n",
    "    for userID, ratings in topN.items():\n",
    "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        topN[(userID)] = ratings[:n]\n",
    "\n",
    "    return topN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwWwWXajcKSF"
   },
   "outputs": [],
   "source": [
    "def DCG(query_relevancy_labels, k):\n",
    "    # Use log with base 2\n",
    "    value=min(k,len(query_relevancy_labels))\n",
    "    sum1=0\n",
    "    for i in range(value):\n",
    "      sum1=sum1+((query_relevancy_labels[i])/(np.log2(2+i)))\n",
    "\n",
    "    return sum1\n",
    "\n",
    "def NDCG(query_relevancy_labels, k):\n",
    "    sorted_list= np.sort(query_relevancy_labels)[::-1]\n",
    "    dcg1 = DCG(query_relevancy_labels, k)\n",
    "    dcg2 = DCG(sorted_list, k)\n",
    "    if dcg2 == 0:\n",
    "      return 0\n",
    "    else:\n",
    "      return dcg1/dcg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ys0Z2aJl5Dyn"
   },
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WLC0Z7J6vFB"
   },
   "outputs": [],
   "source": [
    "def ndcg_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    dcg = dict()\n",
    "    ndcg = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        rel=[]\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        for _, true_r in user_ratings:\n",
    "          if true_r>=threshold:\n",
    "            rel.append(true_r)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "        #print(rel)\n",
    "\n",
    "        ndcg[uid] = NDCG(rel, k)\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        #recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eq3StZBiY7p0"
   },
   "source": [
    "# Initial Run of the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_random_split(df, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x7f22b803fc90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = surprise.Dataset.load_from_df(train, reader=Reader(rating_scale=(1,5)))\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NeQPST3RahyO"
   },
   "outputs": [],
   "source": [
    "my_seed = 0\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "reader = Reader(rating_scale=(1,5),)\n",
    "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ogb2s23AyN7A"
   },
   "outputs": [],
   "source": [
    "my_seed = 0\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "raw_ratings = data.raw_ratings\n",
    "random.shuffle(raw_ratings)\n",
    "threshold = int(.8 * len(raw_ratings))\n",
    "A_raw_ratings = raw_ratings[:threshold]\n",
    "B_raw_ratings = raw_ratings[threshold:]\n",
    "data.raw_ratings = A_raw_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FUxrM3xPbJ1H",
    "outputId": "421c0f37-229e-4598-ce9b-6c5c5b6e9704"
   },
   "outputs": [],
   "source": [
    "len(A_raw_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "suMHsDo_bP9e",
    "outputId": "5dfb32ac-12a7-4b5b-a2d0-e0d1c0d16110"
   },
   "outputs": [],
   "source": [
    "len(B_raw_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CaeTLXW-wDCd",
    "outputId": "344d7ebd-5cdc-4dd1-c94a-46fbd8082231"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'k': [1, 2, 5, 10, 20], 'min_k': [1, 2, 5, 10, 20]}\n",
    "gs = GridSearchCV(KNNBaseline, param_grid, cv=5)\n",
    "gs.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMubmLd7vA0j",
    "outputId": "5a22fd85-a89a-46c3-b52d-d239d9e58682"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params['rmse']['min_k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14oG7XTGcHpG",
    "outputId": "297c784b-627b-4ea0-faed-04a0f89457df"
   },
   "outputs": [],
   "source": [
    "sim_options = {'name': 'pearson_baseline',\n",
    "               'user_based': False}\n",
    "knn = KNNBaseline(k=gs.best_params['rmse']['k'], min_k=gs.best_params['rmse']['min_k'], sim_options=sim_options)\n",
    "# trainset = data.build_full_trainset()\n",
    "knn.fit(train_set)\n",
    "\n",
    "# Compute biased accuracy on A\n",
    "predictions = algo.test(train_set.build_testset())\n",
    "print('Biased accuracy on A,', end='   ')\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "# Compute unbiased accuracy on B\n",
    "testset = data.construct_testset(B_raw_ratings)  # testset is now the set B\n",
    "predictions = algo.test(testset)\n",
    "print('Unbiased accuracy on B,', end=' ')\n",
    "accuracy.rmse(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBaseline at 0x7f22b803b490>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {'name': 'pearson_baseline',\n",
    "               'user_based': False}\n",
    "knn = KNNBaseline(k=gs.best_params['rmse']['k'], min_k=gs.best_params['rmse']['min_k'], sim_options=sim_options)\n",
    "# trainset = data.build_full_trainset()\n",
    "knn.fit(train_set.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASOSP4VAUDB7I</td>\n",
       "      <td>B014IBJKNO</td>\n",
       "      <td>3.992087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A140XVPLRQYKYY</td>\n",
       "      <td>B0058YEJ5K</td>\n",
       "      <td>4.031288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATSUXY7ASCGPY</td>\n",
       "      <td>B014IBJKNO</td>\n",
       "      <td>4.009531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1S4O68F0UG4GA</td>\n",
       "      <td>B001IKJOLW</td>\n",
       "      <td>4.999845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2CP5A30XO5JUO</td>\n",
       "      <td>B009MA34NY</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userID      itemID  prediction\n",
       "0   ASOSP4VAUDB7I  B014IBJKNO    3.992087\n",
       "1  A140XVPLRQYKYY  B0058YEJ5K    4.031288\n",
       "2   ATSUXY7ASCGPY  B014IBJKNO    4.009531\n",
       "3  A1S4O68F0UG4GA  B001IKJOLW    4.999845\n",
       "4  A2CP5A30XO5JUO  B009MA34NY    5.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict(knn, test, usercol='userID', itemcol='itemID')\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.11227919300017675 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "    all_predictions = compute_ranking_predictions(knn, train, usercol='userID', itemcol='itemID', remove_seen=True)\n",
    "    \n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t\t0.097053\n",
      "MAE:\t\t0.013130\n",
      "rsquared:\t0.991063\n",
      "exp var:\t0.991068\n",
      "----\n",
      "MAP:\t0.566537\n",
      "NDCG:\t0.605385\n",
      "Precision@K:\t0.127586\n",
      "Recall@K:\t0.672936\n"
     ]
    }
   ],
   "source": [
    "eval_rmse = rmse(test, predictions)\n",
    "eval_mae = mae(test, predictions)\n",
    "eval_rsquared = rsquared(test, predictions)\n",
    "eval_exp_var = exp_var(test, predictions)\n",
    "\n",
    "k = 10\n",
    "eval_map = map_at_k(test, all_predictions, col_prediction='prediction', k=k)\n",
    "eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=k)\n",
    "eval_precision = precision_at_k(test, all_predictions, col_prediction='prediction', k=k)\n",
    "eval_recall = recall_at_k(test, all_predictions, col_prediction='prediction', k=k)\n",
    "\n",
    "\n",
    "print(\"RMSE:\\t\\t%f\" % eval_rmse,\n",
    "      \"MAE:\\t\\t%f\" % eval_mae,\n",
    "      \"rsquared:\\t%f\" % eval_rsquared,\n",
    "      \"exp var:\\t%f\" % eval_exp_var, sep='\\n')\n",
    "\n",
    "print('----')\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IYGv7U055Duy",
    "outputId": "891081e9-a952-4fff-bef4-efcf09a75de1"
   },
   "outputs": [],
   "source": [
    "newTable = PrettyTable([\"Algorithm\", \"Sparsity\", \"Precision@k\", \"Recall@k\", \"NDCG@k\"]) \n",
    "# precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=4)\n",
    "eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=10)\n",
    "# ndcg_val = ndcg_at_k(predictions, k=10, threshold=4)\n",
    "# precisionk=(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "# recallk=(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "ndcgk=(sum(nd for nd in ndcg_val.values()) / len(ndcg_val))\n",
    "sparse=0.70\n",
    "newTable.add_row([\"KNN_Baseline\", sparse, 0 , 0, eval_ndcg])   \n",
    "print(newTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOjx8HvTZG76"
   },
   "source": [
    "# Model Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OctTbrmfC9_O"
   },
   "outputs": [],
   "source": [
    "def _print(message, verbose):\n",
    "    if verbose:\n",
    "        print(message)\n",
    "    \n",
    "\n",
    "def load_dataset(fp):\n",
    "    df = pd.DataFrame()\n",
    "    try:\n",
    "        df[[\"userID\", \"itemID\", \"rating\", \"timestamp\"]] = pd.read_json(fp)[[\"reviewerID\", \"asin\", \"overall\", \"unixReviewTime\"]]\n",
    "    except:\n",
    "        df = pd.read_json(fp)\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_to_sparsity(df, sparsity_percentage, verbose = False):\n",
    "    # Obtain both usercount and itemcount after filtering\n",
    "    usercount = df[['userID']].groupby('userID', as_index = False).size()\n",
    "    itemcount = df[['itemID']].groupby('itemID', as_index = False).size()\n",
    "\n",
    "    sparsity = 1 - (df.shape[0] / (usercount.shape[0] * itemcount.shape[0]))\n",
    "\n",
    "    _print(f\"After filtering, there are {df.shape[0]} ratings from {usercount.shape[0]} users on {itemcount.shape[0]}\" + \n",
    "           f\" products (sparsity: {sparsity * 100:.3f})\", verbose)\n",
    "    \n",
    "    drop_item_ratings = int(-((1-sparsity_percentage) * (usercount.shape[0] * itemcount.shape[0]) - df.shape[0]))\n",
    "    print(f\"To obtain a sparsity of {sparsity_percentage * 100}% we need to drop {drop_item_ratings} ratings\")\n",
    "    drop_indices = np.random.choice(df.index, size=drop_item_ratings)\n",
    "    df.drop(drop_indices, inplace=True)\n",
    "\n",
    "    sparsity = 1 - (df.shape[0] / (usercount.shape[0] * itemcount.shape[0]))\n",
    "    _print(f\"After dropping cells, there are {df.shape[0]} ratings from {usercount.shape[0]} users on {itemcount.shape[0]}\" + \n",
    "           f\" products (sparsity: {sparsity * 100:.3f})\", verbose)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8XQNB1NC98I"
   },
   "outputs": [],
   "source": [
    "def build_data(df):\n",
    "    \n",
    "    my_seed = 0\n",
    "    random.seed(my_seed)\n",
    "    np.random.seed(my_seed)\n",
    "    \n",
    "    reader = Reader(rating_scale=(1,5))\n",
    "    data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EN9iPksEC95k"
   },
   "outputs": [],
   "source": [
    "def data_loading_pipeline(fp, sparsity_percentage=None, with_writing=False):\n",
    "    \"\"\"\n",
    "    fp: str = Filepointer to desired user-item-ratings json.\n",
    "    sparsity_percentage: float = value between 0-1.\n",
    "    \"\"\"\n",
    "    df = load_dataset(fp)\n",
    "    #df = filter_on_minimal_ratings(df)\n",
    "    df = filter_to_sparsity(df, sparsity_percentage)\n",
    "    data = build_data(df)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLUs2qL2ZNBv"
   },
   "outputs": [],
   "source": [
    "def create_split(i, data):\n",
    "    np.random.seed(i)\n",
    "\n",
    "\n",
    "    raw_ratings = data.raw_ratings\n",
    "    random.shuffle(raw_ratings)\n",
    "    threshold = int(.8 * len(raw_ratings))\n",
    "    A_raw_ratings = raw_ratings[:threshold]\n",
    "    B_raw_ratings = raw_ratings[threshold:]\n",
    "    data.raw_ratings = A_raw_ratings\n",
    "    return A_raw_ratings, B_raw_ratings, data.raw_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3_4-V3FF_RI"
   },
   "outputs": [],
   "source": [
    "metrics_at_sparsity_levels = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbew7zlCC92l",
    "outputId": "02db3e97-b307-4044-ba55-b6fa4d466e1f"
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    pr=[]\n",
    "    re=[]\n",
    "    nd=[]\n",
    "    sparsity_percentage = 0.75\n",
    "    data = data_loading_pipeline(\"AMAZON_FASHION_5.json\", sparsity_percentage)\n",
    "\n",
    "    A_raw_ratings, B_raw_ratings, data.raw_ratings = create_split(i, data)\n",
    "\n",
    "\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'user_based': True  \n",
    "               }\n",
    "\n",
    "    param_grid = {'k': [10, 20, 30, 40, 50, 60, 70, 80, 90], 'min_k': [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "              }\n",
    "    gs = GridSearchCV(KNNBaseline, param_grid, cv=3)\n",
    "\n",
    "    gs.fit(data)\n",
    "    algo=KNNBaseline(sim_options=sim_options, k=gs.best_params['rmse']['k'], min_k=gs.best_params['rmse']['min_k'], verbose=False)\n",
    "\n",
    "    trainset = data.build_full_trainset()\n",
    "    algo.fit(trainset)\n",
    "\n",
    "    # Compute biased accuracy on A\n",
    "    predictions = algo.test(trainset.build_testset())\n",
    "    print('Biased accuracy on A,', end='   ')\n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "    # Compute unbiased accuracy on B\n",
    "    testset = data.construct_testset(B_raw_ratings)  # testset is now the set B\n",
    "    predictions = algo.test(testset)\n",
    "    print('Unbiased accuracy on B,', end=' ')\n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "\n",
    "\n",
    "    newTable = PrettyTable([\"Algorithm\", \"Sparsity\", \"Precision@k\", \"Recall@k\", \"NDCG@k\"]) \n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=4)\n",
    "    ndcg_val = ndcg_at_k(predictions, k=10, threshold=4)\n",
    "    precisionk=(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    recallk=(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "    ndcgk=(sum(nd for nd in ndcg_val.values()) / len(ndcg_val))\n",
    "    pr.append(precisionk)\n",
    "    re.append(recallk)\n",
    "    nd.append(ndcgk)\n",
    "ndcgk = sum(nd) / len(nd)\n",
    "precisionk = sum(pr) / len(pr)\n",
    "recallk = sum(re) / len(re)\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)] = {\n",
    "                                                        \"ndcg\": ndcgk,\n",
    "                                                        \"precision\": precisionk,\n",
    "                                                        \"recall\": recallk}\n",
    "newTable.add_row([\"KNN_Baseline\", sparsity_percentage, precisionk , recallk, ndcgk])   \n",
    "print(newTable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQzlT1XO9PS9",
    "outputId": "f0593472-1a46-43be-be91-f308831f85bc"
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    pr=[]\n",
    "    re=[]\n",
    "    nd=[]\n",
    "    sparsity_percentage = 0.8\n",
    "    data = data_loading_pipeline(\"AMAZON_FASHION_5.json\", sparsity_percentage)\n",
    "\n",
    "    A_raw_ratings, B_raw_ratings, data.raw_ratings = create_split(i, data)\n",
    "\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'user_based': True  \n",
    "               }\n",
    "\n",
    "    param_grid = {'k': [10, 20, 30, 40, 50, 60, 70, 80, 90], 'min_k': [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "              }\n",
    "    gs = GridSearchCV(KNNBaseline, param_grid, cv=3)\n",
    "\n",
    "    gs.fit(data)\n",
    "    algo=KNNBaseline(sim_options=sim_options, k=gs.best_params['rmse']['k'], min_k=gs.best_params['rmse']['min_k'])\n",
    "\n",
    "    trainset = data.build_full_trainset()\n",
    "    algo.fit(trainset)\n",
    "\n",
    "    # Compute biased accuracy on A\n",
    "    predictions = algo.test(trainset.build_testset())\n",
    "    print('Biased accuracy on A,', end='   ')\n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "    # Compute unbiased accuracy on B\n",
    "    testset = data.construct_testset(B_raw_ratings)  # testset is now the set B\n",
    "    predictions = algo.test(testset)\n",
    "    print('Unbiased accuracy on B,', end=' ')\n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "\n",
    "\n",
    "    newTable = PrettyTable([\"Algorithm\", \"Sparsity\", \"Precision@k\", \"Recall@k\", \"NDCG@k\"]) \n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=4)\n",
    "    ndcg_val = ndcg_at_k(predictions, k=10, threshold=4)\n",
    "    precisionk=(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    recallk=(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "    ndcgk=(sum(nd for nd in ndcg_val.values()) / len(ndcg_val))\n",
    "    pr.append(precisionk)\n",
    "    re.append(recallk)\n",
    "    nd.append(ndcgk)\n",
    "ndcgk = sum(nd) / len(nd)\n",
    "precisionk = sum(pr) / len(pr)\n",
    "recallk = sum(re) / len(re)\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)] = {\n",
    "                                                        \"ndcg\": ndcgk,\n",
    "                                                        \"precision\": precisionk,\n",
    "                                                        \"recall\": recallk}\n",
    "newTable.add_row([\"KNN_Baseline\", sparsity_percentage, precisionk , recallk, ndcgk])   \n",
    "print(newTable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pi90qq6j9PPm",
    "outputId": "58176644-9c27-4f7a-8113-af2fff1852c7"
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    pr=[]\n",
    "    re=[]\n",
    "    nd=[]\n",
    "    sparsity_percentage = 0.85\n",
    "    data = data_loading_pipeline(\"AMAZON_FASHION_5.json\", sparsity_percentage)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    A_raw_ratings, B_raw_ratings, data.raw_ratings = create_split(i, data)\n",
    "\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'user_based': True  \n",
    "               }\n",
    "\n",
    "    param_grid = {'k': [10, 20, 30, 40, 50, 60, 70, 80, 90], 'min_k': [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "              }\n",
    "    gs = GridSearchCV(KNNBaseline, param_grid, cv=3)\n",
    "\n",
    "    gs.fit(data)\n",
    "    algo=KNNBaseline(sim_options=sim_options, k=gs.best_params['rmse']['k'], min_k=gs.best_params['rmse']['min_k'])\n",
    "\n",
    "    trainset = data.build_full_trainset()\n",
    "    algo.fit(trainset)\n",
    "\n",
    "    # Compute biased accuracy on A\n",
    "    predictions = algo.test(trainset.build_testset())\n",
    "    print('Biased accuracy on A,', end='   ')\n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "    # Compute unbiased accuracy on B\n",
    "    testset = data.construct_testset(B_raw_ratings)  # testset is now the set B\n",
    "    predictions = algo.test(testset)\n",
    "    print('Unbiased accuracy on B,', end=' ')\n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "\n",
    "\n",
    "    newTable = PrettyTable([\"Algorithm\", \"Sparsity\", \"Precision@k\", \"Recall@k\", \"NDCG@k\"]) \n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=4)\n",
    "    ndcg_val = ndcg_at_k(predictions, k=10, threshold=4)\n",
    "    precisionk=(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    recallk=(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "    ndcgk=(sum(nd for nd in ndcg_val.values()) / len(ndcg_val))\n",
    "    pr.append(precisionk)\n",
    "    re.append(recallk)\n",
    "    nd.append(ndcgk)\n",
    "ndcgk = sum(nd) / len(nd)\n",
    "precisionk = sum(pr) / len(pr)\n",
    "recallk = sum(re) / len(re)\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)] = {\n",
    "                                                        \"ndcg\": ndcgk,\n",
    "                                                        \"precision\": precisionk,\n",
    "                                                        \"recall\": recallk}\n",
    "newTable.add_row([\"KNN_Baseline\", sparsity_percentage, precisionk , recallk, ndcgk])   \n",
    "print(newTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJbFsCQj9PNJ",
    "outputId": "32743e4b-c3be-435f-c5ea-c7441064829a"
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    pr=[]\n",
    "    re=[]\n",
    "    nd=[]\n",
    "    sparsity_percentage = 0.9\n",
    "    data = data_loading_pipeline(\"AMAZON_FASHION_5.json\", sparsity_percentage)\n",
    "\n",
    "\n",
    "\n",
    "    A_raw_ratings, B_raw_ratings, data.raw_ratings = create_split(i, data)\n",
    "\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'user_based': True  \n",
    "               }\n",
    "\n",
    "    param_grid = {'k': [10, 20, 30, 40, 50, 60, 70, 80, 90], 'min_k': [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "              }\n",
    "    gs = GridSearchCV(KNNBaseline, param_grid, cv=3)\n",
    "\n",
    "    gs.fit(data)\n",
    "    algo=KNNBaseline(sim_options=sim_options, k=gs.best_params['rmse']['k'], min_k=gs.best_params['rmse']['min_k'])\n",
    "\n",
    "    trainset = data.build_full_trainset()\n",
    "    algo.fit(trainset)\n",
    "\n",
    "    # Compute biased accuracy on A\n",
    "    predictions = algo.test(trainset.build_testset())\n",
    "    print('Biased accuracy on A,', end='   ')\n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "    # Compute unbiased accuracy on B\n",
    "    testset = data.construct_testset(B_raw_ratings)  # testset is now the set B\n",
    "    predictions = algo.test(testset)\n",
    "    print('Unbiased accuracy on B,', end=' ')\n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "\n",
    "\n",
    "    newTable = PrettyTable([\"Algorithm\", \"Sparsity\", \"Precision@k\", \"Recall@k\", \"NDCG@k\"]) \n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=4)\n",
    "    ndcg_val = ndcg_at_k(predictions, k=10, threshold=4)\n",
    "    precisionk=(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    recallk=(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "    ndcgk=(sum(nd for nd in ndcg_val.values()) / len(ndcg_val))\n",
    "    pr.append(precisionk)\n",
    "    re.append(recallk)\n",
    "    nd.append(ndcgk)\n",
    "ndcgk = sum(nd) / len(nd)\n",
    "precisionk = sum(pr) / len(pr)\n",
    "recallk = sum(re) / len(re)\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)] = {\n",
    "                                                        \"ndcg\": ndcgk,\n",
    "                                                        \"precision\": precisionk,\n",
    "                                                        \"recall\": recallk}\n",
    "newTable.add_row([\"KNN_Baseline\", sparsity_percentage, precisionk , recallk, ndcgk])   \n",
    "print(newTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v26Ef-bm9PKM",
    "outputId": "7a95fe94-1bd0-49fc-de1c-020e22c9d15c"
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    pr=[]\n",
    "    re=[]\n",
    "    nd=[]\n",
    "    sparsity_percentage = 0.95\n",
    "    data = data_loading_pipeline(\"AMAZON_FASHION_5.json\", sparsity_percentage)\n",
    "\n",
    "\n",
    "\n",
    "    A_raw_ratings, B_raw_ratings, data.raw_ratings = create_split(i, data)\n",
    "\n",
    "    sim_options = {'name': 'pearson_baseline',\n",
    "               'user_based': True  \n",
    "               }\n",
    "\n",
    "    param_grid = {'k': [10, 20, 30, 40, 50, 60, 70, 80, 90], 'min_k': [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "              }\n",
    "    gs = GridSearchCV(KNNBaseline, param_grid, cv=3)\n",
    "\n",
    "    gs.fit(data)\n",
    "    algo=KNNBaseline(sim_options=sim_options, k=gs.best_params['rmse']['k'], min_k=gs.best_params['rmse']['min_k'])\n",
    "\n",
    "    trainset = data.build_full_trainset()\n",
    "    algo.fit(trainset)\n",
    "\n",
    "    # Compute biased accuracy on A\n",
    "    predictions = algo.test(trainset.build_testset())\n",
    "    print('Biased accuracy on A,', end='   ')\n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "    # Compute unbiased accuracy on B\n",
    "    testset = data.construct_testset(B_raw_ratings)  # testset is now the set B\n",
    "    predictions = algo.test(testset)\n",
    "    print('Unbiased accuracy on B,', end=' ')\n",
    "    accuracy.rmse(predictions)\n",
    "\n",
    "\n",
    "\n",
    "    newTable = PrettyTable([\"Algorithm\", \"Sparsity\", \"Precision@k\", \"Recall@k\", \"NDCG@k\"]) \n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=4)\n",
    "    ndcg_val = ndcg_at_k(predictions, k=10, threshold=4)\n",
    "    precisionk=(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    recallk=(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "    ndcgk=(sum(nd for nd in ndcg_val.values()) / len(ndcg_val))\n",
    "    pr.append(precisionk)\n",
    "    re.append(recallk)\n",
    "    nd.append(ndcgk)\n",
    "ndcgk = sum(nd) / len(nd)\n",
    "precisionk = sum(pr) / len(pr)\n",
    "recallk = sum(re) / len(re)\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)] = {\n",
    "                                                        \"ndcg\": ndcgk,\n",
    "                                                        \"precision\": precisionk,\n",
    "                                                        \"recall\": recallk}\n",
    "newTable.add_row([\"KNN_Baseline\", sparsity_percentage, precisionk , recallk, ndcgk])   \n",
    "print(newTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "PkWhB1zgFd1J",
    "outputId": "36851f1d-58d1-44e1-f445-126f8bbea9fd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sparsity_levels = list(map(lambda x: float(x), metrics_at_sparsity_levels))\n",
    "plt.plot(sparsity_levels, list(map(lambda x: x['ndcg'], metrics_at_sparsity_levels.values())), label=\"ndcg@10\", marker = \"o\")\n",
    "#plt.plot(sparsity_levels, list(map(lambda x: x['map'], metrics_at_sparsity_levels.values())), label=\"map@10\", marker = \"o\")\n",
    "plt.plot(sparsity_levels, list(map(lambda x: x['recall'], metrics_at_sparsity_levels.values())), label=\"recall@10\", marker = \"o\")\n",
    "plt.plot(sparsity_levels, list(map(lambda x: x['precision'], metrics_at_sparsity_levels.values())), label=\"precision@10\", marker = \"o\")\n",
    "\n",
    "plt.title(\"Metrics as function of Sparsity\")\n",
    "plt.xlabel(\"Sparsity %\")\n",
    "plt.legend()\n",
    "plt.savefig(\"../metrics_over_sparsity.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7qj-eRHFdx2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled20.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
