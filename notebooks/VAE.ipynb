{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f400b81",
   "metadata": {
    "id": "ogeTPu0m7Em6"
   },
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b793d5",
   "metadata": {},
   "source": [
    "This notebook is based on [this example](https://github.com/microsoft/recommenders/blob/main/examples/02_model_collaborative_filtering/standard_vae_deep_dive.ipynb) and adapted to our needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4c830e",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd39e30d",
   "metadata": {},
   "source": [
    "To run this notebook on Windows, either use Google Colab or make use of the Docker file in [this](https://github.com/microsoft/recommenders/tree/main/tools/docker) repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433c303a",
   "metadata": {
    "id": "XcSewSRc7Em7"
   },
   "source": [
    "# Standard Variational Autoencoders for Collaborative Filtering on Amazong Fashion dataset.\n",
    "This notebook accompanies the paper \"*A Hybrid Variational Autoencoder for Collaborative Filtering*\" by Kilol Gupta, Mukund Y. Raghuprasad, Pankhuri Kumar [[Gupta et al.,2018]](https://arxiv.org/pdf/1808.01006.pdf). We will study a part of this paper, more specific, the derivation of the \"*Standard Variational Autoencoder*\" [[Gupta et al.,2018, chapter 5.1]](https://arxiv.org/pdf/1808.01006.pdf) .\n",
    "\n",
    "The \"*Standard Variational Autoencoder*\" is enhanced using $\\mathbf \\beta$-VAE [[Higgins et al, 2016]](https://openreview.net/pdf?id=Sy2fzU9gl), [[Burgess et al, 2018]](https://arxiv.org/pdf/1804.03599.pdf). Also, for tuning the parameter $\\mathbf \\beta$ an annealing methodology is used based on [[Bowman et al, 2015]](https://arxiv.org/pdf/1511.06349.pdf) and [[Liang, Dawen, et al,2018]](https://dl.acm.org/doi/pdf/10.1145/3178876.3186150?casa_token=Heh8W001edYAAAAA:P_y4buj0zb2ml8GpDXONkrc3EYEBOxgjZNAJOuqes60aeJ4C1Vg1Wq5Eh6mkCXhxNKp38pO_eUw).\n",
    "\n",
    "\n",
    "In this notebook, we will show a complete self-contained example of training a \"*Standard Variational Autoencoder*\" with a simple ELBO function/loss (described in the original paper) and the prosposed extention of it. The public [Amazon dataset](https://nijianmo.github.io/amazon/index.html) is used for training and evaluating our model, with subcategory Fashion. For this notebook it is assumed that the reader has basic knowledge about VAE [[Kingma et al, 2013]](https://arxiv.org/pdf/1312.6114.pdf).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdfb1c5",
   "metadata": {
    "id": "wqTaWp1M7Em8"
   },
   "source": [
    "# 0 Global Settings and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abfed7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pzWbu_nfd1GG",
    "outputId": "2e710d84-c5e3-40bc-b1d9-5c61dec7d207"
   },
   "outputs": [],
   "source": [
    "# download the necessary libraries\n",
    "! pip install tensorflow==2.2.0-rc1\n",
    "! pip install keras==2.3.1\n",
    "! pip install papermill\n",
    "! pip install recommenders[examples,gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccda9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy==1.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337bf03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AXyb1KV27Em9",
    "outputId": "063e8693-feee-4a4e-abf4-c60638a3f7f1"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import papermill as pm\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.transforms import Affine2D\n",
    "from recommenders.datasets.python_splitters import numpy_stratified_split\n",
    "from recommenders.datasets.sparse import AffinityMatrix\n",
    "from recommenders.datasets.split_utils import min_rating_filter_pandas\n",
    "from recommenders.evaluation.python_evaluation import (\n",
    "    map_at_k,\n",
    "    ndcg_at_k,\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    ")\n",
    "from recommenders.models.vae.standard_vae import StandardVAE\n",
    "from recommenders.utils.constants import SEED as DEFAULT_SEED\n",
    "from recommenders.utils.python_utils import binarize\n",
    "from recommenders.utils.timer import Timer\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
    "print(\"Keras version: {}\".format(keras.__version__))\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f4c3d",
   "metadata": {
    "id": "AH6Cjbta7EnB",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# top 10 items to recommend, the fashion dataset does not contain too many products.\n",
    "TOP_K = 10\n",
    "\n",
    "# Model parameters\n",
    "HELDOUT_USERS_VAL_PERC = 0.1  # CHANGE FOR DIFFERENT DATASIZE\n",
    "HELDOUT_USERS_TEST_PERC = 0.2  # CHANGE FOR DIFFERENT DATASIZE\n",
    "INTERMEDIATE_DIM = 50\n",
    "LATENT_DIM = 10\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# temporary Path to save the optimal model's weights\n",
    "WEIGHTS_PATH = os.path.join(\".save_weights.hdf5\")\n",
    "\n",
    "SEED = 98765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardRealValueVAE(StandardVAE):\n",
    "    \"\"\"\n",
    "    Using inheritence we overloaded the methods to create real valued output for the VAE. \n",
    "    We used a MSE loss instead of a BCE and applied a softmax activation function on the last layer. \n",
    "    Additionally we applied a Lambda layer to scale the softmax layer to be in the 1-5 range.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_rating, max_rating, *args, **kwargs):\n",
    "        self.min_rating = min_rating\n",
    "        self.max_rating = max_rating\n",
    "        self.scale_to_rating = Lambda(self._scale_rating)\n",
    "        super(StandardRealValueVAE, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def _scale_rating(self, x):\n",
    "        return x * (self.max_rating - self.min_rating) + self.min_rating\n",
    "\n",
    "    def _create_model(self):\n",
    "        \"\"\"Build and compile model.\"\"\"\n",
    "        # Encoding\n",
    "        self.x = Input(shape=(self.original_dim,))\n",
    "        self.dropout_encoder = Dropout(self.drop_encoder)(self.x)\n",
    "        self.h = Dense(self.intermediate_dim, activation=\"tanh\")(\n",
    "            self.dropout_encoder)\n",
    "        self.z_mean = Dense(self.latent_dim)(self.h)\n",
    "        self.z_log_var = Dense(self.latent_dim)(self.h)\n",
    "\n",
    "        # Sampling\n",
    "        self.z = Lambda(self._take_sample, output_shape=(self.latent_dim,))(\n",
    "            [self.z_mean, self.z_log_var]\n",
    "        )\n",
    "\n",
    "        # Decoding\n",
    "        self.h_decoder = Dense(self.intermediate_dim, activation=\"tanh\")\n",
    "        self.dropout_decoder = Dropout(self.drop_decoder)\n",
    "        self.x_bar = Dense(self.original_dim, activation=\"softmax\")\n",
    "        self.h_decoded = self.h_decoder(self.z)\n",
    "        self.h_decoded_ = self.dropout_decoder(self.h_decoded)\n",
    "        self.x_decoded = self.x_bar(self.h_decoded_)\n",
    "        self.x_decoded = self.scale_to_rating(self.x_decoded)\n",
    "\n",
    "        # Training\n",
    "        self.model = Model(self.x, self.x_decoded)\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss=self._get_vae_loss,\n",
    "        )\n",
    "\n",
    "    def _get_vae_loss(self, x, x_bar):\n",
    "        \"\"\"Calculate negative ELBO (NELBO).\"\"\"\n",
    "        # Reconstruction error: logistic log likelihood\n",
    "        reconst_loss = self.original_dim * mean_squared_error(x, x_bar)\n",
    "\n",
    "        # Kullback–Leibler divergence\n",
    "        kl_loss = 0.5 * K.sum(\n",
    "            -1 - self.z_log_var + K.square(self.z_mean) + K.exp(self.z_log_var), axis=-1\n",
    "        )\n",
    "\n",
    "        return reconst_loss + self.beta * kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ff4fe",
   "metadata": {
    "id": "C5ADl4Cu7EnD"
   },
   "source": [
    "# 1 Standard-VAE algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0728e13",
   "metadata": {
    "id": "oU2r5-vexUh7"
   },
   "source": [
    "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of ratings for each item from user u. The original notebook used a binarized click matrix, but to create a better comparison between the different CF recommender systems, we decided to create a VAE with real valued output between 1 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6849d51",
   "metadata": {
    "id": "ErGfeXjWxsfz"
   },
   "source": [
    "__Standard-VAE Model__: Autoencoder based recommendation is an unsupervised model attempting to reconstruct its input data in the output layer. The middle layer (bottleneck layer) is used as a salient feature representation of the input data. In this notebook, we study the standard variational autoencoder and derive the variational lower bound loss function of the standard variational autoencoder. The output of the SVAE is a probability distribution over the K items. This differs from the normal VAE that has the final output as the reconstructed input. So, the SVAE takes the user ratings in the form of a click matrix, $\\mathbf{x}_u$, as inputs and then are encoded to learn the mean, $\\mathbf{m}_u$, and the standard deviation, $\\mathbf{\\sigma}_u$, of the K-dimensional latent representation through the encoder function, $\\mathbf{g}_\\phi(\\mathbf{x}_u)$ = $\\mathbf{m}_u$, $\\mathbf{\\sigma}_u$. In other words, the latent vector for each user,  $\\mathbf{z}_u$, is sampled from the Gaussian distribution, where $\\mathbf{z}_u$ ∼ N($\\mathbf{m}_u$, $\\mathbf{\\sigma}_u$). Then, the decoder function, $\\mathbf{f}_\\theta$($\\mathbf{z}_u$) = $\\mathbf{\\pi}_u$, is used to decode the latent vector from K-dimensional space to a probability distribution $\\mathbf{\\pi}_u$ in the original N-dimensional space. As a result, we get the probabilities of each of the N products being viewed by each user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620a4afa",
   "metadata": {
    "id": "ysxIWUcI7EnD"
   },
   "source": [
    "The objective __function/loss__ used in the model is the __ELBO__:\n",
    "\n",
    "$$Loss= \\log p_\\theta(\\mathbf{x}_u | \\mathbf{z}_u) -  KL (q(\\mathbf{z}_u)||p(\\mathbf{z}_u|\\mathbf{x}_u))$$\n",
    "\n",
    "where:\n",
    "* $\\mathbf{x}_u$: the product feature vector\n",
    "* $\\mathbf{z}_u$: latent representation of $\\mathbf{x}_u$\n",
    "* $KL$: The Kullback-Leibler divergence measure\n",
    "\n",
    "The first part of the ELBO equation considers the logistic log-likelihood for a product given its latent representation (reconstruction error), while the second KL term can be viewed as a regularization part. Our goal is to maximize __ELBO__, which is equivalent to minimizing the negative ELBO  (__NELBO__).\n",
    "\n",
    "The logistic log-likelihood fuction is given as, $$\\log p_\\theta(\\mathbf{x}_u | \\mathbf{z}_u) = \\sum_{i} \\mathbf{x}_{ui} \\log \\mathbf{\\sigma}(\\mathbf{f}_{ui}) + (1 - \\mathbf{x}_{ui}) \\log(1 - \\mathbf{\\sigma}(\\mathbf{f}_{ui})) $$\n",
    "\n",
    "where:\n",
    "* $\\mathbf{\\sigma}(\\mathbf{x}) = 1 / (1+ \\exp(-\\mathbf{x}))$ taken over all the products i.\n",
    "\n",
    "In addition, we extended the **ELBO** by introducing a parameter $\\beta$  ([Higgins et al, 2016](https://openreview.net/pdf?id=Sy2fzU9gl), [Burgess et al, 2018](https://arxiv.org/pdf/1804.03599.pdf) ) to control the strength of regularization:\n",
    "\n",
    "$$\n",
    "Loss= \\log p_\\theta(\\mathbf{x}_u | \\mathbf{z}_u) - \\mathbf{\\beta}  KL (q(\\mathbf{z}_u)||p(\\mathbf{z}_u|\\mathbf{x}_u))\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Τhe regularization view of the **ELBO** introduces a\n",
    "trade-off between how well we can fit the data and how close the\n",
    "approximate posterior stays to the prior during learning. By introducing the parameter $\\mathbf{\\beta}$ < 1, we are weakening the influence of the prior constraint. As a result, the model is less able to generate novel user histories by ancestral sampling. It is important to mention that our goal is not to maximize likelihood or generate imagined user histories, rather, our goal is to make good recommendations. So by treating $\\mathbf{\\beta}$ as a free regularization parameter yields significant improvements in performance. We propose two different experiments.\n",
    "\n",
    "At first, the training of the model is being done by setting $\\mathbf{\\beta}$=1 [[Gupta et al.,2018, chapter 5.1]](https://arxiv.org/pdf/1808.01006.pdf).\n",
    "\n",
    "\n",
    "Finally, we introduce a simple heuristic for tuning $\\mathbf{\\beta}$. We anneal the KL divergence all the way to a specific value of $\\mathbf{\\beta}$, reaching that value at around 80% of the total number of epochs used during the training process. Then we identify the best performing  $\\mathbf{\\beta}$  based on the peak validation metric, and retrain the model with the same annealing schedule, but for the rest of epochs we are not increasing  $\\mathbf{\\beta}$  after reaching its optimal value.\n",
    "\n",
    "It can be hard to imagine how to evaluate a recommender system. The primary concern of recommender systems is that they need to be able to put relevant items very high up the list of recommendations. So we need rank-aware metrics to select recommenders that aim at these two primary goals:\n",
    "\n",
    "1.\tWhere does the recommender place the items it suggests?\n",
    "2.\tHow good is the recommender at modeling relative preference?\n",
    "\n",
    "So, the rank-aware metric we use is the Normalized Discounted Cumulative Gain. NDCG value putting highly relevant documents high up the recommended lists. It is able to use the fact that some documents are “more” relevant than others. It compares the predicted rank of the held-out items with their true rank. The metric recall, primarily concerned with being good at finding things. We need metrics that emphasis being good at finding and ranking things, like NDCG. That's why we emphasize in NDCG.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdda3e05",
   "metadata": {
    "id": "xd0RPMhD7EnE"
   },
   "source": [
    "# 2 Keras implementation of Standard VAE\n",
    "\n",
    "For the implementation of the model, Keras package is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db6f05f",
   "metadata": {
    "id": "r7Eb3TY1ytdW"
   },
   "source": [
    "# 3 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f714a63",
   "metadata": {
    "id": "qCKNsE9z7EnE"
   },
   "source": [
    "### 3.1 Load data and split\n",
    "\n",
    "We load the data and create train / validation / test splits following strong generalization:\n",
    "\n",
    "- We split all unique users into training users and heldout users (i.e. validation and test users)\n",
    "\n",
    "- By using the lists of these users, we obtain corresponding training data and heldout data.\n",
    "\n",
    "- We train models using the entire rating vector of the training users.\n",
    "\n",
    "- To evaluate, we take part of the reviews from heldout (validation and test) data to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen ratings from the heldout data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb6739",
   "metadata": {
    "id": "YV_SaTQeRkkK"
   },
   "source": [
    "#### 3.1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a2f8c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SFSY6UrI7EnF",
    "outputId": "83ad82a7-b0ea-4b7c-8e56-c117ce21b060"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[[\"userID\", \"itemID\", \"rating\", \"timestamp\"]] = pd.read_json(\n",
    "    \"../data/AMAZON_FASHION_5.json\")[[\"reviewerID\", \"asin\", \"overall\", \"unixReviewTime\"]]\n",
    "df.drop_duplicates(subset=[\"userID\", \"itemID\"], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8cb5ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4T_sSWa2C_b",
    "outputId": "d27f2f5d-5aea-4552-9c3e-4a36fb7d691d"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000fd973",
   "metadata": {
    "id": "7EXP5hSAewnA"
   },
   "source": [
    "#### 3.1.2 Data Filtering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a9f700",
   "metadata": {
    "id": "Y3ng_FifVxHr"
   },
   "source": [
    "For the data filtering we are using the below 3 steps which are recommended by the original paper [[Liang, Dawen, et al,2018]](https://dl.acm.org/doi/pdf/10.1145/3178876.3186150?casa_token=zul5haircsAAAAAA:iIKn7y-xWwSeqaP-MmmyUaJoJuNZX9Fx1aXeFJwkwtMpVDCrPMW3kZjuYo1LKhSuMeUMNf1mbP2o).\n",
    "\n",
    "\n",
    "We have to make sure that :\n",
    " - user-to-product interactions with rating <=3.5 are filtered out. Applying this filtering we make sure that if a product is rated less than 3.5 from the users that they watched this product, it will not be contained in the final click matrix. If we do not apply this filter, the final click matrix will be even sparser.\n",
    " - the users who clicked less than 5 products are filtered out.\n",
    " - the products which are not clicked by any user are filtered out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41781755",
   "metadata": {},
   "outputs": [],
   "source": [
    "usercount = df[['userID']].groupby('userID', as_index=False).size()\n",
    "itemcount = df[['itemID']].groupby('itemID', as_index=False).size()\n",
    "print(df.shape, usercount.shape, itemcount.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6065884",
   "metadata": {
    "id": "hwIiD5BL2IBY"
   },
   "outputs": [],
   "source": [
    "# Keep users who clicked on at least 3 items (original dataset was supposed to have atleast 5 reviews/ratings,\n",
    "# but since this was also reviews on subtypes of the same product and we had to drop these duplicates, we have to refilter)\n",
    "df = min_rating_filter_pandas(df, min_rating=3, filter_by=\"user\")\n",
    "\n",
    "# Keep products that were clicked on by at least on 1 user\n",
    "df = min_rating_filter_pandas(df, min_rating=1, filter_by=\"item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e87e1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQhnqzU8j03b",
    "outputId": "4790fd65-6bc1-4a28-ff0c-113a2aed5a72"
   },
   "outputs": [],
   "source": [
    "# Obtain both usercount and itemcount after filtering\n",
    "usercount = df[['userID']].groupby('userID', as_index=False).size()\n",
    "itemcount = df[['itemID']].groupby('itemID', as_index=False).size()\n",
    "print(df.shape, usercount.shape, itemcount.shape)\n",
    "\n",
    "density = 1. * df.shape[0] / (usercount.shape[0] * itemcount.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d ratings from %d users on %d products (sparsity: %.3f%%)\" %\n",
    "      (df.shape[0], usercount.shape[0], itemcount.shape[0], (1 - density) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f422d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"../data/AMAZON_FASHION_5.71.268.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec10653",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "oQWDlySeiBet",
    "outputId": "90a37a32-94ab-4f23-e5ac-1b0662d1f001"
   },
   "outputs": [],
   "source": [
    "# Binarize the data (only keep ratings >= 4)\n",
    "df_preferred = df[df['rating'] > 3.5]\n",
    "print(df_preferred.shape)\n",
    "df_low_rating = df[df['rating'] <= 3.5]\n",
    "\n",
    "\n",
    "df_preferred.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dec916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_preferred\n",
    "\n",
    "# Obtain both usercount and itemcount after filtering\n",
    "usercount = df[['userID']].groupby('userID', as_index=False).size()\n",
    "itemcount = df[['itemID']].groupby('itemID', as_index=False).size()\n",
    "print(df.shape, usercount.shape, itemcount.shape)\n",
    "\n",
    "density = 1. * df.shape[0] / (usercount.shape[0] * itemcount.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d ratings from %d users on %d products (sparsity: %.3f%%)\" %\n",
    "      (df.shape[0], usercount.shape[0], itemcount.shape[0], (1 - density) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523067f9",
   "metadata": {
    "id": "ha1fHIx_nqH8"
   },
   "source": [
    "#### 3.1.3 Split data\n",
    "\n",
    "For data slitting we use:\n",
    "- 600 (~ 10%) users in validation set\n",
    "- 600 (~ 10%) users in testing set\n",
    "- the rest of them (~ 80%) in training set\n",
    "\n",
    "Since the model is trained using the click history of the training users, we have to make sure that the products that exist in the validation and test sets are the products that exist in the train set. In other words, validation and test set should not contain products that do not exist in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80cd29a",
   "metadata": {
    "id": "keLEIqb-LMoi"
   },
   "outputs": [],
   "source": [
    "unique_users = sorted(df.userID.unique())\n",
    "np.random.seed(SEED)\n",
    "unique_users = np.random.permutation(unique_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c5afe6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3PswIHyDkidS",
    "outputId": "117cc912-39b5-401e-a288-46bcb2c4e235"
   },
   "outputs": [],
   "source": [
    "# Create train/validation/test users\n",
    "# The order of splitting is val, test and then training to solve the rounding error for int() on line 5, 6\n",
    "n_users = len(unique_users)\n",
    "print(\"Number of unique users:\", n_users)\n",
    "HELDOUT_USERS_VAL = int(HELDOUT_USERS_VAL_PERC * n_users)\n",
    "HELDOUT_USERS_TEST = int(HELDOUT_USERS_TEST_PERC * n_users)\n",
    "\n",
    "val_users = unique_users[:HELDOUT_USERS_VAL]\n",
    "print(\"\\nNumber of validation users:\", len(val_users))\n",
    "\n",
    "test_users = unique_users[HELDOUT_USERS_VAL:(\n",
    "    HELDOUT_USERS_VAL+HELDOUT_USERS_TEST)]\n",
    "print(\"\\nNumber of test users:\", len(test_users))\n",
    "\n",
    "train_users = unique_users[(HELDOUT_USERS_VAL+HELDOUT_USERS_TEST):]\n",
    "print(\"\\nNumber of training users:\", len(train_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262c2d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vj2_zn_6km2R",
    "outputId": "f386e7c2-72ad-4777-b7fb-afa67f65f992"
   },
   "outputs": [],
   "source": [
    "# For training set keep only users that are in train_users list\n",
    "train_set = df.loc[df['userID'].isin(train_users)]\n",
    "print(\"Number of training observations: \", train_set.shape[0])\n",
    "\n",
    "# For validation set keep only users that are in val_users list\n",
    "val_set = df.loc[df['userID'].isin(val_users)]\n",
    "print(\"\\nNumber of validation observations: \", val_set.shape[0])\n",
    "\n",
    "# For test set keep only users that are in test_users list\n",
    "test_set = df.loc[df['userID'].isin(test_users)]\n",
    "print(\"\\nNumber of test observations: \", test_set.shape[0])\n",
    "\n",
    "# train_set/val_set/test_set contain user - product interactions with rating 4 or 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9abb98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbK7DimNKL1s",
    "outputId": "851ddfd9-5928-44cf-f3e6-247b87a9e479"
   },
   "outputs": [],
   "source": [
    "# Obtain list of unique products used in training set\n",
    "unique_train_items = pd.unique(train_set['itemID'])\n",
    "print(\"Number of unique items that rated in training set\", unique_train_items.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6356c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kmKaUumcDDL5",
    "outputId": "219c52fe-626a-46e9-ad05-311f699f904e"
   },
   "outputs": [],
   "source": [
    "# For validation set keep only products that used in training set\n",
    "val_set = val_set.loc[val_set['itemID'].isin(unique_train_items)]\n",
    "print(\"Number of validation observations after filtering: \", val_set.shape[0])\n",
    "\n",
    "# For test set keep only products that used in training set\n",
    "test_set = test_set.loc[test_set['itemID'].isin(unique_train_items)]\n",
    "print(\"\\nNumber of test observations after filtering: \", test_set.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2806fe1",
   "metadata": {
    "id": "0eKkN1F-RHSJ"
   },
   "source": [
    "## 3.2 Click matrix generation\n",
    "\n",
    "From section 3.1 we end up with 3 datasets train_set, val_set and test_set.  For our model we need to give a click matrix as an input that contains only 0-s and 1-s, where each row represents a user and each column represents a product.\n",
    "So, the click matrix contains the preferences of the user, marking each cell with 0 when the user did not enjoy (ratings below 3.5) or did not watch a product and with 1 when the user enjoyed a product (ratings above 3.5).\n",
    "\n",
    "The training set will be a click matrix containing full historicity of all training users. However, the test set and validation set should be splitted into train and test parts. As a result, we get 4 datasets:\n",
    "- val_data_tr\n",
    "- val_data_te\n",
    "- test_data_tr\n",
    "- test_data_te\n",
    "\n",
    "\n",
    "'val_data_tr' contains 75% of the the preferred products (products marked as 1 in the click matrix) per user.\n",
    "The rest 25% of the preffered products are contained into the 'val_data_te'. The same splitting is followed for test set.\n",
    "\n",
    "The 'val_data_tr' is given as an input for our model at the end of each epoch. The result of the model is a 'reconstructed_val_data_tr', which contains the products recommended for each user by the model. In order to evaluate the performance of the model, at the end of each epoch, we compare the 'reconstructed_val_data_tr' (predicted recommendations by the model) with the 'val_data_te' (true product preferences of each user) using NDCG@k metric.\n",
    "\n",
    "For the final evaluation of the model the 'test_data_tr' and 'test_data_te' are being used. As we described before, the 'test_data_tr' is given as an input for the model and returns the 'reconstructed_test_data_tr' dataset with the recommendations made by the model. Then, the 'reconstructed_test_data_tr' is compared with 'test_data_te' through different metrics:\n",
    "- MAP\n",
    "- NDCG@k\n",
    "- Recall@k\n",
    "- Precision@k\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2db2f8",
   "metadata": {
    "id": "_cYDwcy3ohEu"
   },
   "outputs": [],
   "source": [
    "# Instantiate the sparse matrix generation for train, validation and test sets\n",
    "# use list of unique items from training set for all sets\n",
    "am_train = AffinityMatrix(df=train_set, items_list=unique_train_items)\n",
    "\n",
    "am_val = AffinityMatrix(df=val_set, items_list=unique_train_items)\n",
    "\n",
    "am_test = AffinityMatrix(df=test_set, items_list=unique_train_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab9997",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oygrnMOcpZxD",
    "outputId": "9d44ee11-be78-45dc-da76-9a6aecd12ae2"
   },
   "outputs": [],
   "source": [
    "# Obtain the sparse matrix for train, validation and test sets\n",
    "train_data, _, _ = am_train.gen_affinity_matrix()\n",
    "print(train_data.shape)\n",
    "\n",
    "val_data, val_map_users, val_map_items = am_val.gen_affinity_matrix()\n",
    "print(val_data.shape)\n",
    "\n",
    "test_data, test_map_users, test_map_items = am_test.gen_affinity_matrix()\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad13b93",
   "metadata": {
    "id": "WZwuDmuAsos3"
   },
   "outputs": [],
   "source": [
    "# Split validation and test data into training and testing parts\n",
    "val_data_tr, val_data_te = numpy_stratified_split(\n",
    "    val_data, ratio=0.75, seed=SEED)\n",
    "test_data_tr, test_data_te = numpy_stratified_split(\n",
    "    test_data, ratio=0.75, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b5d50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_uBNSJ7VX2KX",
    "outputId": "464e8e9b-392e-478b-c2db-f867784d2e29"
   },
   "outputs": [],
   "source": [
    "# Just checking\n",
    "print(np.sum(val_data))\n",
    "print(np.sum(val_data_tr))\n",
    "print(np.sum(val_data_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1430701",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtDsnJuMTzNk",
    "outputId": "9164b57a-6a4a-488f-be41-8d3c5358331d"
   },
   "outputs": [],
   "source": [
    "# Just checking\n",
    "print(np.sum(test_data))\n",
    "print(np.sum(test_data_tr))\n",
    "print(np.sum(test_data_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e6033c",
   "metadata": {
    "id": "8tdIpYbvPr_7"
   },
   "source": [
    "# 4 Train Standard-VAE using Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc845ef8",
   "metadata": {
    "id": "2nWkhdT4CfUA"
   },
   "source": [
    "__Model Architecture:__\n",
    "\n",
    "For \"MovieLens-1M dataset\", we set both the generative function and the inference model to be 3-layer multilayer perceptron (MLP) with symmetrical architecture.\n",
    "The generative function is a [70 -> 200 -> n_items] MLP, which means the inference function is a [n_items -> 200 -> 70] MLP. Thus the overall architecture for the Multi-VAE is [n_items -> 200 -> 70 -> 200 -> n_items].\n",
    "\n",
    "Also, Dropout is applied both in encoder and decoder to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8540dbf",
   "metadata": {
    "id": "phz3XJTE5LbY"
   },
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1027c1e3",
   "metadata": {
    "id": "ZZUSmIm2O0aq"
   },
   "source": [
    "## 4.1 Standard VAE without annealing  (initial approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b21ac",
   "metadata": {
    "id": "eT_MEhETgF2a"
   },
   "source": [
    "Firstly, we train Standard-VAE model using constant $\\mathbf \\beta$= 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b70aac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tzclS2sgVqa",
    "outputId": "0fc9dd41-8c60-4b61-8dc6-28a348f8b2cd"
   },
   "outputs": [],
   "source": [
    "model_without_anneal = StandardRealValueVAE(min_rating=1,\n",
    "                                            max_rating=5,\n",
    "                                            # Number of unique users in the training set\n",
    "                                            n_users=train_data.shape[0],\n",
    "                                            # Number of unique items in the training set\n",
    "                                            original_dim=train_data.shape[1],\n",
    "                                            intermediate_dim=INTERMEDIATE_DIM,\n",
    "                                            latent_dim=LATENT_DIM,\n",
    "                                            n_epochs=EPOCHS,\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            k=TOP_K,\n",
    "                                            verbose=0,\n",
    "                                            seed=SEED,\n",
    "                                            save_path=WEIGHTS_PATH,\n",
    "                                            drop_encoder=0.5,\n",
    "                                            drop_decoder=0.5,\n",
    "                                            annealing=False,\n",
    "                                            beta=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c32226",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QPaR4bK0f2fi",
    "outputId": "d55e2dea-ca88-45fb-8f80-3c9dfc88c919"
   },
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    model_without_anneal.fit(x_train=train_data,\n",
    "                             x_valid=val_data,\n",
    "                             x_val_tr=val_data_tr,\n",
    "                             x_val_te=val_data_te,  # with the original ratings\n",
    "                             mapper=am_val\n",
    "                             )\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6d215",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "68RGXLBMqFEH",
    "outputId": "0cbfaf95-49ed-486c-c1b3-9f6b08b68184"
   },
   "outputs": [],
   "source": [
    "model_without_anneal.display_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e3056f",
   "metadata": {
    "id": "rpAEwHkwMoz9"
   },
   "outputs": [],
   "source": [
    "ndcg_val_without_anneal = model_without_anneal.ndcg_per_epoch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d7cc2",
   "metadata": {
    "id": "HGIwwhxgi30H"
   },
   "source": [
    "#### Prediction and Evaluation of Standard-VAE model using constant $\\beta$ = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705d5d02",
   "metadata": {
    "id": "stK8DSn1xyJn"
   },
   "source": [
    "Evaluate with recommending 5 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171d3c4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUgTyeviqe2O",
    "outputId": "f6ce4863-d18b-45a0-ccdf-23999231df16"
   },
   "outputs": [],
   "source": [
    "eval_k = 5\n",
    "with Timer() as t:\n",
    "    # Model prediction on the training part of test set\n",
    "    top_k = model_without_anneal.recommend_k_items(x=test_data_tr,\n",
    "                                                   k=eval_k,\n",
    "                                                   remove_seen=True)\n",
    "    # Convert sparse matrix back to df\n",
    "    top_k_df = am_test.map_back_sparse(top_k, kind='prediction')\n",
    "    # use test_data_te_, with the original ratings\n",
    "    test_df = am_test.map_back_sparse(test_data_te, kind='ratings')\n",
    "\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(t))\n",
    "# Use the ranking metrics for evaluation\n",
    "eval_map_1 = map_at_k(test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "eval_ndcg_1 = ndcg_at_k(\n",
    "    test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "eval_precision_1 = precision_at_k(\n",
    "    test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "eval_recall_1 = recall_at_k(\n",
    "    test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "\n",
    "print(f\"MAP@{eval_k}:\\t\\t{eval_map_1:.5f}\",\n",
    "      f\"NDCG@{eval_k}:\\t\\t{eval_ndcg_1:.5f}\",\n",
    "      f\"Precision@{eval_k}:\\t{eval_precision_1:.5f}\",\n",
    "      f\"Recall@{eval_k}: \\t{eval_recall_1:.5f}\", sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2211d9a9",
   "metadata": {
    "id": "zupjoESMwNn4"
   },
   "source": [
    "Evaluate with recommending 10 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d61da72",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i96QHiDm1HcK",
    "outputId": "079ba07c-f0f1-4675-927d-39403204f0ea"
   },
   "outputs": [],
   "source": [
    "eval_k = 10\n",
    "with Timer() as t:\n",
    "    # Model prediction on the training part of test set\n",
    "    top_k = model_without_anneal.recommend_k_items(x=test_data_tr,\n",
    "                                                   k=eval_k,\n",
    "                                                   remove_seen=True)\n",
    "    # Convert sparse matrix back to df\n",
    "    top_k_df = am_test.map_back_sparse(top_k, kind='prediction')\n",
    "    # use test_data_te_, with the original ratings\n",
    "    test_df = am_test.map_back_sparse(test_data_te, kind='ratings')\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(t))\n",
    "\n",
    "# Use the ranking metrics for evaluation\n",
    "eval_map_2 = map_at_k(test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "eval_ndcg_2 = ndcg_at_k(\n",
    "    test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "eval_precision_2 = precision_at_k(\n",
    "    test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "eval_recall_2 = recall_at_k(\n",
    "    test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "\n",
    "print(f\"MAP@{eval_k}:\\t\\t{eval_map_2:.5f}\",\n",
    "      f\"NDCG@{eval_k}:\\t{eval_ndcg_2:.5f}\",\n",
    "      f\"Precision@{eval_k}:\\t{eval_precision_2:.5f}\",\n",
    "      f\"Recall@{eval_k}: \\t{eval_recall_2:.5f}\", sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0342e8",
   "metadata": {
    "id": "87Fg9wt50fga"
   },
   "source": [
    "## 4.2 Standard VAE with annealing\n",
    "We are going to use annealing procedure for finding the optimal $\\mathbf \\beta$.\n",
    "\n",
    "Now, in order to find the optimal $\\beta$, we train our model using annealing with anneal_cap equal 1.0.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690d54d",
   "metadata": {
    "id": "Q9xXAAON0izE"
   },
   "outputs": [],
   "source": [
    "model_with_anneal = StandardRealValueVAE(min_rating=1,\n",
    "                                         max_rating=5,\n",
    "                                         # Number of unique users in the training set\n",
    "                                         n_users=train_data.shape[0],\n",
    "                                         # Number of unique items in the training set\n",
    "                                         original_dim=train_data.shape[1],\n",
    "                                         intermediate_dim=INTERMEDIATE_DIM,\n",
    "                                         latent_dim=LATENT_DIM,\n",
    "                                         n_epochs=EPOCHS,\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         k=TOP_K,\n",
    "                                         verbose=0,\n",
    "                                         seed=SEED,\n",
    "                                         save_path=WEIGHTS_PATH,\n",
    "                                         drop_encoder=0.5,\n",
    "                                         drop_decoder=0.5,\n",
    "                                         annealing=True,\n",
    "                                         anneal_cap=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff741c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zq3fgxQE1lBw",
    "outputId": "29a8f742-83a1-494b-b959-a3490af71120"
   },
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    model_with_anneal.fit(x_train=train_data,\n",
    "                          x_valid=val_data,\n",
    "                          x_val_tr=val_data_tr,\n",
    "                          x_val_te=val_data_te,  # with the original ratings\n",
    "                          mapper=am_val\n",
    "                          )\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbdcff7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "zQe8H2DfvBlv",
    "outputId": "d19b75d4-0d52-4eda-db7b-615ac290a63a"
   },
   "outputs": [],
   "source": [
    "model_with_anneal.display_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62570a19",
   "metadata": {
    "id": "m9hKfKiyyCwG"
   },
   "outputs": [],
   "source": [
    "ndcg_val_with_anneal = model_with_anneal.ndcg_per_epoch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbebdd8",
   "metadata": {
    "id": "o9xC4nUCZumS"
   },
   "source": [
    "Using the optimal beta as anneal cap , we retrain our model.\n",
    "\n",
    "When NDCG@k of validation set reach a peak, the weights of the model are saved. Using this model we evaluate the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653d15ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nxTweT9pvErE",
    "outputId": "8e494df8-3346-43bf-e26d-725ce6923381"
   },
   "outputs": [],
   "source": [
    "# Get optimal beta\n",
    "optimal_beta = model_with_anneal.get_optimal_beta()\n",
    "print(\"The optimal beta is: \", optimal_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf89b9f",
   "metadata": {
    "id": "B9BJACElaU9h"
   },
   "outputs": [],
   "source": [
    "model_optimal_beta = StandardRealValueVAE(min_rating=1,\n",
    "                                          max_rating=5,\n",
    "                                          # Number of unique users in the training set\n",
    "                                          n_users=train_data.shape[0],\n",
    "                                          # Number of unique items in the training set\n",
    "                                          original_dim=train_data.shape[1],\n",
    "                                          intermediate_dim=INTERMEDIATE_DIM,\n",
    "                                          latent_dim=LATENT_DIM,\n",
    "                                          n_epochs=EPOCHS,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          k=TOP_K,\n",
    "                                          verbose=0,\n",
    "                                          seed=SEED,\n",
    "                                          save_path=WEIGHTS_PATH,\n",
    "                                          drop_encoder=0.5,\n",
    "                                          drop_decoder=0.5,\n",
    "                                          annealing=True,\n",
    "                                          anneal_cap=optimal_beta,\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5136218",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8lj7tOqB-o9L",
    "outputId": "5ba3e9e1-2dd8-41c5-f12d-9ca4b1a9ca62"
   },
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    model_optimal_beta.fit(x_train=train_data,\n",
    "                           x_valid=val_data,\n",
    "                           x_val_tr=val_data_tr,\n",
    "                           x_val_te=val_data_te,  # with the original ratings\n",
    "                           mapper=am_val\n",
    "                           )\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d13c3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "k9Xovr9zbvin",
    "outputId": "e554d440-cb2e-4ea9-c6ac-6914e228424c"
   },
   "outputs": [],
   "source": [
    "model_optimal_beta.display_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9580646a",
   "metadata": {
    "id": "GHCkX097D3jZ"
   },
   "outputs": [],
   "source": [
    "ndcg_val_optimal_beta = model_optimal_beta.ndcg_per_epoch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf14b7a",
   "metadata": {
    "id": "I1ZwFx-JEXam"
   },
   "source": [
    "#### Prediction and Evaluation of Standard-VAE model using the optimal $\\beta$ with annealing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e42f4",
   "metadata": {
    "id": "cMX8dc8vEmE-"
   },
   "source": [
    "Evaluate with recommending 10 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c2acd7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8chehXIr4FCD",
    "outputId": "5a9aa286-3527-4365-fa38-7aa33f1a7f42"
   },
   "outputs": [],
   "source": [
    "eval_k = 10\n",
    "with Timer() as t:\n",
    "    # Model prediction on the training part of test set\n",
    "    top_k = model_optimal_beta.recommend_k_items(x=test_data_tr,\n",
    "                                                 k=eval_k,\n",
    "                                                 remove_seen=True)\n",
    "    # Convert sparse matrix back to df\n",
    "    top_k_df = am_test.map_back_sparse(top_k, kind='prediction')\n",
    "    # use test_data_te_, with the original ratings\n",
    "    test_df = am_test.map_back_sparse(test_data_te, kind='ratings')\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(t))\n",
    "\n",
    "# Use the ranking metrics for evaluation\n",
    "eval_map_3 = map_at_k(test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "eval_ndcg_3 = ndcg_at_k(\n",
    "    test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "eval_precision_3 = precision_at_k(\n",
    "    test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "eval_recall_3 = recall_at_k(\n",
    "    test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "\n",
    "print(f\"MAP@{eval_k}:\\t\\t{eval_map_3:.5f}\",\n",
    "      f\"NDCG@{eval_k}:\\t{eval_ndcg_3:.5f}\",\n",
    "      f\"Precision@{eval_k}:\\t{eval_precision_3:.5f}\",\n",
    "      f\"Recall@{eval_k}: \\t{eval_recall_3:.5f}\", sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad0d08c",
   "metadata": {
    "id": "cMX8dc8vEmE-"
   },
   "source": [
    "Evaluate with recommending 5 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b164a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8chehXIr4FCD",
    "outputId": "5a9aa286-3527-4365-fa38-7aa33f1a7f42"
   },
   "outputs": [],
   "source": [
    "eval_k = 5\n",
    "with Timer() as t:\n",
    "    # Model prediction on the training part of test set\n",
    "    top_k = model_optimal_beta.recommend_k_items(x=test_data_tr,\n",
    "                                                 k=eval_k,\n",
    "                                                 remove_seen=True)\n",
    "    # Convert sparse matrix back to df\n",
    "    top_k_df = am_test.map_back_sparse(top_k, kind='prediction')\n",
    "    # use test_data_te_, with the original ratings\n",
    "    test_df = am_test.map_back_sparse(test_data_te, kind='ratings')\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(t))\n",
    "\n",
    "# Use the ranking metrics for evaluation\n",
    "eval_map_3 = map_at_k(test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "eval_ndcg_3 = ndcg_at_k(\n",
    "    test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "eval_precision_3 = precision_at_k(\n",
    "    test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "eval_recall_3 = recall_at_k(\n",
    "    test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "\n",
    "print(f\"MAP@{eval_k}:\\t\\t{eval_map_3:.5f}\",\n",
    "      f\"NDCG@{eval_k}:\\t\\t{eval_ndcg_3:.5f}\",\n",
    "      f\"Precision@{eval_k}:\\t{eval_precision_3:.5f}\",\n",
    "      f\"Recall@{eval_k}: \\t{eval_recall_3:.5f}\", sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05faf0",
   "metadata": {
    "id": "jNPefXO7wZP2"
   },
   "source": [
    "# 5 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c1cdd5",
   "metadata": {
    "id": "RoiM8KeCvTPg"
   },
   "source": [
    "Through this notebook, it is proven that the VAE using annealing outperforms the model without annealing (using $\\mathbf \\beta$=1). Specifically, the results of evaluting the test set, for the the 2 different approaches, are:\n",
    "\n",
    "| Model | NDCG@100  |NDCG@10 |\n",
    "| --- | --- | --- |\n",
    "| Standard-VAE (wihtout annealing, β=1)| 0.392 | 0.446 |\n",
    "| Standard-VAE (with annealing, optimal β)| 0.443 | 0.496 |\n",
    "\n",
    "\n",
    "This annealing procedure is used as an efficient way to tune the parameter $\\mathbf \\beta$. Otherwise, training multiple models using different values of $\\mathbf \\beta$ can be really time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efedeccb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "I66wqKPRhJ2g",
    "lines_to_next_cell": 2,
    "outputId": "f84aab99-8348-422e-b78c-19c4af4ccf6f"
   },
   "outputs": [],
   "source": [
    "# Plot setup\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Plot NDCG@k of validation sets for three models\n",
    "plt.plot(ndcg_val_without_anneal, color='b',\n",
    "         linestyle='-', label='without anneal')\n",
    "plt.plot(ndcg_val_with_anneal, color='g',\n",
    "         linestyle='-', label='with anneal at β=1')\n",
    "plt.plot(ndcg_val_optimal_beta, color='r',\n",
    "         linestyle='-', label='with anneal at optimal β')\n",
    "\n",
    "# Add plot title and axis names\n",
    "plt.title('VALIDATION NDCG@100 FOR DIFFERENT MODELS \\n', size=16)\n",
    "plt.xlabel('Epochs', size=14)\n",
    "plt.ylabel('NDCG@10', size=14)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019fb969",
   "metadata": {
    "id": "oQ2vJIqq4CdG"
   },
   "source": [
    "# Now we are going to vary the Sparsity\n",
    "We will be doing this by splitting the difference (i.e. 100% - ~75% = 25%) up in 5 equal steps of 5% each. This would result in 75%, 80%, 85%, 90% and 95% sparsity. At each step we will perform a full round of training, validating and testing to see the performance of the VAE under data sparseness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a121463b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HxfLMhv4B3j",
    "outputId": "4e0bfc0d-760c-4fda-f4ad-27ea4e302bed"
   },
   "outputs": [],
   "source": [
    "VERBOSE = False\n",
    "\n",
    "\n",
    "def _print(message):\n",
    "    if VERBOSE:\n",
    "        print(message)\n",
    "\n",
    "\n",
    "def load_dataset(fp):\n",
    "    df = pd.DataFrame()\n",
    "    try:\n",
    "        df[[\"userID\", \"itemID\", \"rating\", \"timestamp\"]] = pd.read_json(\n",
    "            fp)[[\"reviewerID\", \"asin\", \"overall\", \"unixReviewTime\"]]\n",
    "    except:\n",
    "        df = pd.read_json(fp)\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_on_minimal_ratings(df):\n",
    "    # Keep users who clicked on at least 3 products\n",
    "    df = min_rating_filter_pandas(df, min_rating=3, filter_by=\"user\")\n",
    "\n",
    "    # Keep products that were clicked on by at least on 1 user\n",
    "    df = min_rating_filter_pandas(df, min_rating=1, filter_by=\"item\")\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_to_sparsity(df, sparsity_percentage, verbose=False):\n",
    "    # Obtain both usercount and itemcount after filtering\n",
    "    usercount = df[['userID']].groupby('userID', as_index=False).size()\n",
    "    itemcount = df[['itemID']].groupby('itemID', as_index=False).size()\n",
    "\n",
    "    sparsity = 1 - (df.shape[0] / (usercount.shape[0] * itemcount.shape[0]))\n",
    "\n",
    "    _print(f\"After filtering, there are {df.shape[0]} ratings from {usercount.shape[0]} users on {itemcount.shape[0]}\" +\n",
    "           f\" products (sparsity: {sparsity * 100:.3f})\")\n",
    "\n",
    "    drop_item_ratings = int(-((1-sparsity_percentage) *\n",
    "                            (usercount.shape[0] * itemcount.shape[0]) - df.shape[0]))\n",
    "    _print(\n",
    "        f\"To obtain a sparsity of {sparsity_percentage * 100}% we need to drop {drop_item_ratings} ratings\")\n",
    "    # Only remove ratings where the item is present more than 1 time in the dataset. This way items won't be fully omitted from the dataset.\n",
    "    drop_indices = np.random.choice(df[df.itemID.isin(\n",
    "        (df.groupby('itemID').count() > 1).index)].index, size=drop_item_ratings)\n",
    "    # Future work: make sure stratified subsampling to make sure you won't drop products completely\n",
    "    df.drop(drop_indices, inplace=True)\n",
    "\n",
    "    sparsity = 1 - (df.shape[0] / (usercount.shape[0] * itemcount.shape[0]))\n",
    "    _print(f\"After dropping cells, there are {df.shape[0]} ratings from {usercount.shape[0]} users on {itemcount.shape[0]}\" +\n",
    "           f\" products (sparsity: {sparsity * 100:.3f})\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_dataframe(df, val_percentage=0.1, test_percentage=0.2):\n",
    "    unique_users = sorted(df.userID.unique())\n",
    "    np.random.seed(SEED)\n",
    "    unique_users = np.random.permutation(unique_users)\n",
    "\n",
    "    # Create train/validation/test users\n",
    "    # The order of splitting is val, test and then training to solve the rounding error for int() on line 5, 6\n",
    "    n_users = len(unique_users)\n",
    "    _print(f\"Number of unique users: {n_users}\")\n",
    "    HELDOUT_USERS_VAL = int(val_percentage * n_users)\n",
    "    HELDOUT_USERS_TEST = int(test_percentage * n_users)\n",
    "\n",
    "    val_users = unique_users[:HELDOUT_USERS_VAL]\n",
    "    _print(f\"\\nNumber of validation users: {len(val_users)}\")\n",
    "\n",
    "    test_users = unique_users[HELDOUT_USERS_VAL:(\n",
    "        HELDOUT_USERS_VAL+HELDOUT_USERS_TEST)]\n",
    "    _print(f\"\\nNumber of test users: {len(test_users)}\")\n",
    "\n",
    "    train_users = unique_users[(HELDOUT_USERS_VAL+HELDOUT_USERS_TEST):]\n",
    "    _print(f\"\\nNumber of training users: {len(train_users)}\")\n",
    "\n",
    "    # For training set keep only users that are in train_users list\n",
    "    train_set = df.loc[df['userID'].isin(train_users)]\n",
    "    _print(f\"Number of training observations: {train_set.shape[0]}\")\n",
    "\n",
    "    # For validation set keep only users that are in val_users list\n",
    "    val_set = df.loc[df['userID'].isin(val_users)]\n",
    "    _print(f\"\\nNumber of validation observations: {val_set.shape[0]}\")\n",
    "\n",
    "    # For test set keep only users that are in test_users list\n",
    "    test_set = df.loc[df['userID'].isin(test_users)]\n",
    "    _print(f\"\\nNumber of test observations: {test_set.shape[0]}\")\n",
    "\n",
    "    # Obtain list of unique products used in training set\n",
    "    unique_train_items = pd.unique(train_set['itemID'])\n",
    "    _print(\n",
    "        f\"Number of unique items that rated in training set {unique_train_items.size}\")\n",
    "\n",
    "    # For validation set keep only products that used in training set\n",
    "    val_set = val_set.loc[val_set['itemID'].isin(unique_train_items)]\n",
    "    _print(\n",
    "        f\"Number of validation observations after filtering: {val_set.shape[0]}\")\n",
    "\n",
    "    # For test set keep only products that used in training set\n",
    "    test_set = test_set.loc[test_set['itemID'].isin(unique_train_items)]\n",
    "    _print(\n",
    "        f\"\\nNumber of test observations after filtering: {test_set.shape[0]}\")\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "\n",
    "def create_matrix(train_set, val_set, test_set):\n",
    "    # Instantiate the sparse matrix generation for train, validation and test sets\n",
    "    # use list of unique items from training set for all sets\n",
    "    unique_train_items = pd.unique(train_set['itemID'])\n",
    "    am_train = AffinityMatrix(df=train_set, items_list=unique_train_items)\n",
    "    am_val = AffinityMatrix(df=val_set, items_list=unique_train_items)\n",
    "    am_test = AffinityMatrix(df=test_set, items_list=unique_train_items)\n",
    "\n",
    "    # Obtain the sparse matrix for train, validation and test sets\n",
    "    train_data, _, _ = am_train.gen_affinity_matrix()\n",
    "    _print(train_data.shape)\n",
    "\n",
    "    val_data, val_map_users, val_map_items = am_val.gen_affinity_matrix()\n",
    "    _print(val_data.shape)\n",
    "\n",
    "    test_data, test_map_users, test_map_items = am_test.gen_affinity_matrix()\n",
    "    _print(test_data.shape)\n",
    "\n",
    "    # Split validation and test data into training and testing parts\n",
    "    val_data_tr, val_data_te = numpy_stratified_split(\n",
    "        val_data, ratio=0.75, seed=SEED)\n",
    "    test_data_tr, test_data_te = numpy_stratified_split(\n",
    "        test_data, ratio=0.75, seed=SEED)\n",
    "    return train_data, am_val, val_data, val_data_tr, val_data_te, am_test, test_data, test_data_tr, test_data_te\n",
    "\n",
    "\n",
    "def data_loading_pipeline(fp, sparsity_percentage=None, with_writing=False):\n",
    "    \"\"\"\n",
    "    fp: str = Filepointer to desired user-item-ratings json.\n",
    "    sparsity_percentage: float = value between 0-1.\n",
    "    \"\"\"\n",
    "    df = load_dataset(fp)\n",
    "    df = filter_on_minimal_ratings(df)\n",
    "    df = filter_to_sparsity(df, sparsity_percentage)\n",
    "    train_set, val_set, test_set = split_dataframe(df)\n",
    "    train_data, am_val, val_data, val_data_tr, val_data_te_ratings, am_test, test_data, test_data_tr, test_data_te_ratings = create_matrix(\n",
    "        train_set, val_set, test_set)\n",
    "    return train_data, am_val, val_data, val_data_tr, val_data_te_ratings, am_test, test_data, test_data_tr, test_data_te_ratings\n",
    "\n",
    "\n",
    "data_loading_pipeline(\"../data/AMAZON_FASHION_5.json\", 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961dc793",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_at_sparsity_levels = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bdf165",
   "metadata": {},
   "source": [
    "### Training with 75% sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc81cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, val_data, val_data_tr, val_data_te_ratings, am_val):\n",
    "    model_with_anneal = StandardRealValueVAE(\n",
    "        min_rating=1,\n",
    "        max_rating=5,\n",
    "        # Number of unique users in the training set\n",
    "        n_users=train_data.shape[0],\n",
    "        # Number of unique items in the training set\n",
    "        original_dim=train_data.shape[1],\n",
    "        intermediate_dim=INTERMEDIATE_DIM,\n",
    "        latent_dim=LATENT_DIM,\n",
    "        n_epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        k=TOP_K,\n",
    "        verbose=0,\n",
    "        seed=SEED,\n",
    "        save_path=WEIGHTS_PATH,\n",
    "        drop_encoder=0.5,\n",
    "        drop_decoder=0.5,\n",
    "        annealing=True,\n",
    "        anneal_cap=1.0)\n",
    "    with Timer() as t:\n",
    "        model_with_anneal.fit(x_train=train_data,\n",
    "                              x_valid=val_data,\n",
    "                              x_val_tr=val_data_tr,\n",
    "                              x_val_te=val_data_te_ratings,  # with the original ratings\n",
    "                              mapper=am_val)\n",
    "    print(\"Took {} seconds for training.\".format(t))\n",
    "    return model_with_anneal\n",
    "\n",
    "\n",
    "def tune(optimal_beta, train_data, val_data, val_data_tr, val_data_te_ratings, am_val):\n",
    "    model_optimal_beta = StandardRealValueVAE(\n",
    "        min_rating=1,\n",
    "        max_rating=5,\n",
    "        # Number of unique users in the training set\n",
    "        n_users=train_data.shape[0],\n",
    "        # Number of unique items in the training set\n",
    "        original_dim=train_data.shape[1],\n",
    "        intermediate_dim=INTERMEDIATE_DIM,\n",
    "        latent_dim=LATENT_DIM,\n",
    "        n_epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        k=TOP_K,\n",
    "        verbose=0,\n",
    "        seed=SEED,\n",
    "        save_path=WEIGHTS_PATH,\n",
    "        drop_encoder=0.5,\n",
    "        drop_decoder=0.5,\n",
    "        annealing=True,\n",
    "        anneal_cap=optimal_beta)\n",
    "\n",
    "    with Timer() as t:\n",
    "        model_optimal_beta.fit(x_train=train_data,\n",
    "                               x_valid=val_data,\n",
    "                               x_val_tr=val_data_tr,\n",
    "                               x_val_te=val_data_te_ratings,  # with the original ratings\n",
    "                               mapper=am_val\n",
    "                               )\n",
    "        print(\"Took {} seconds for training.\".format(t))\n",
    "        return model_optimal_beta\n",
    "\n",
    "\n",
    "def evaluate(model_optimal_beta, test_data_tr, test_data_te_ratings, am_test, eval_k):\n",
    "    with Timer() as t:\n",
    "        # Model prediction on the training part of test set\n",
    "        top_k = model_optimal_beta.recommend_k_items(x=test_data_tr,\n",
    "                                                     k=eval_k,\n",
    "                                                     remove_seen=True)\n",
    "        # Convert sparse matrix back to df\n",
    "        top_k_df = am_test.map_back_sparse(top_k, kind='prediction')\n",
    "        # use test_data_te_, with the original ratings\n",
    "        test_df = am_test.map_back_sparse(test_data_te_ratings, kind='ratings')\n",
    "\n",
    "    print(\"Took {} seconds for prediction.\".format(t))\n",
    "\n",
    "    # Use the ranking metrics for evaluation\n",
    "    eval_map = map_at_k(test_df, top_k_df,\n",
    "                        col_prediction='prediction', k=eval_k)\n",
    "    eval_ndcg = ndcg_at_k(\n",
    "        test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "    eval_precision = precision_at_k(\n",
    "        test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "    eval_recall = recall_at_k(\n",
    "        test_df, top_k_df, col_prediction='prediction', k=eval_k)\n",
    "\n",
    "    return eval_map, eval_ndcg, eval_precision, eval_recall\n",
    "\n",
    "\n",
    "def train_tune_eval_pipeline(sparsity_percentage, run_n_times=20):\n",
    "    maps, ndcgs, precisions, recalls = np.zeros(run_n_times), np.zeros(\n",
    "        run_n_times), np.zeros(run_n_times), np.zeros(run_n_times)\n",
    "\n",
    "    eval_k = TOP_K\n",
    "    for i in range(run_n_times):\n",
    "        SEED = i\n",
    "        VERBOSE = False\n",
    "        if i == 0:\n",
    "            VERBOSE = True  # Print data messages once\n",
    "\n",
    "        train_data, am_val, val_data, val_data_tr, val_data_te_ratings, am_test, test_data, test_data_tr, test_data_te_ratings = data_loading_pipeline(\n",
    "            \"../data/AMAZON_FASHION_5.json\", sparsity_percentage)\n",
    "\n",
    "        model_with_anneal = train(\n",
    "            train_data, val_data, val_data_tr, val_data_te_ratings, am_val)\n",
    "\n",
    "        model_optimal_beta = tune(model_with_anneal.get_optimal_beta(\n",
    "        ), train_data, val_data, val_data_tr, val_data_te_ratings, am_val)\n",
    "\n",
    "        eval_map, eval_ndcg, eval_precision, eval_recall = evaluate(\n",
    "            model_optimal_beta, test_data_tr, test_data_te_ratings, am_test, eval_k)\n",
    "\n",
    "        maps[i] = eval_map\n",
    "        ndcgs[i] = eval_ndcg\n",
    "        precisions[i] = eval_precision\n",
    "        recalls[i] = eval_recall\n",
    "\n",
    "    model_with_anneal.display_metrics()\n",
    "    model_optimal_beta.display_metrics()\n",
    "    print(f\"mean MAP@{eval_k}:\\t\\t{maps.mean():.5f}\",\n",
    "          f\"mean NDCG@{eval_k}:\\t{ndcgs.mean():.5f}\",\n",
    "          f\"mean Precision@{eval_k}:\\t{precisions.mean():.5f}\",\n",
    "          f\"mean Recall@{eval_k}: \\t{recalls.mean():.5f}\", sep='\\n')\n",
    "    return maps, ndcgs, precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0664c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_percentage = 0.75\n",
    "maps, ndcgs, precisions, recalls = train_tune_eval_pipeline(\n",
    "    sparsity_percentage, run_n_times=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f39fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps, ndcgs, precisions, recalls = train_tune_eval_pipeline(sparsity_percentage, run_n_times=20)\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)] = dict()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)][\"map\"] = maps.tolist()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)][\"ndcgs\"] = ndcgs.tolist()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)\n",
    "                           ][\"precisions\"] = precisions.tolist()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)\n",
    "                           ][\"recalls\"] = recalls.tolist()\n",
    "\n",
    "\n",
    "with open(\"../results/results_vae.json\", \"w\") as fp:\n",
    "    json.dump(metrics_at_sparsity_levels, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed99bcb",
   "metadata": {},
   "source": [
    "### Training with 80% sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_percentage = 0.80\n",
    "with open(\"../results/results_vae.json\", \"r\") as fp:\n",
    "    metrics_at_sparsity_levels = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eeea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps, ndcgs, precisions, recalls = train_tune_eval_pipeline(\n",
    "    sparsity_percentage)\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)] = dict()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)][\"map\"] = maps.tolist()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)][\"ndcgs\"] = ndcgs.tolist()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)\n",
    "                           ][\"precisions\"] = precisions.tolist()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)\n",
    "                           ][\"recalls\"] = recalls.tolist()\n",
    "\n",
    "\n",
    "with open(\"../results/results_vae.json\", \"w\") as fp:\n",
    "    json.dump(metrics_at_sparsity_levels, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6ef56",
   "metadata": {},
   "source": [
    "### Training with 85% sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d639468",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_percentage = 0.85\n",
    "\n",
    "with open(\"../results/results_vae.json\", \"r\") as fp:\n",
    "    metrics_at_sparsity_levels = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00f5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps, ndcgs, precisions, recalls = train_tune_eval_pipeline(\n",
    "    sparsity_percentage)\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)] = dict()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)][\"map\"] = maps.tolist()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)][\"ndcgs\"] = ndcgs.tolist()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)\n",
    "                           ][\"precisions\"] = precisions.tolist()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)\n",
    "                           ][\"recalls\"] = recalls.tolist()\n",
    "\n",
    "\n",
    "with open(\"../results/results_vae.json\", \"w\") as fp:\n",
    "    json.dump(metrics_at_sparsity_levels, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdb2ba5",
   "metadata": {},
   "source": [
    "### Training with 90% sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34728bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_percentage = 0.90\n",
    "\n",
    "with open(\"../results/results_vae.json\", \"r\") as fp:\n",
    "    metrics_at_sparsity_levels = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd49701",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps, ndcgs, precisions, recalls = train_tune_eval_pipeline(\n",
    "    sparsity_percentage)\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)] = dict()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)][\"map\"] = maps.tolist()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)][\"ndcgs\"] = ndcgs.tolist()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)\n",
    "                           ][\"precisions\"] = precisions.tolist()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)\n",
    "                           ][\"recalls\"] = recalls.tolist()\n",
    "\n",
    "with open(\"../results/results_vae.json\", \"w\") as fp:\n",
    "    json.dump(metrics_at_sparsity_levels, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2447c",
   "metadata": {},
   "source": [
    "### Training with 95% sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0d6760",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_percentage = 0.95\n",
    "with open(\"../results/results_vae.json\", \"r\") as fp:\n",
    "    metrics_at_sparsity_levels = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa978b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps, ndcgs, precisions, recalls = train_tune_eval_pipeline(\n",
    "    sparsity_percentage)\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)] = dict()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)][\"map\"] = maps.tolist()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)][\"ndcgs\"] = ndcgs.tolist()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)\n",
    "                           ][\"precisions\"] = precisions.tolist()\n",
    "metrics_at_sparsity_levels[str(sparsity_percentage)\n",
    "                           ][\"recalls\"] = recalls.tolist()\n",
    "\n",
    "with open(\"../results/results_vae.json\", \"w\") as fp:\n",
    "    json.dump(metrics_at_sparsity_levels, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a87ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparsity_levels = list(map(lambda x: float(x), metrics_at_sparsity_levels))\n",
    "# plt.plot(sparsity_levels, list(map(lambda x: x['ndcg'], metrics_at_sparsity_levels.values())), label=\"ndcg@10\", marker = \"o\")\n",
    "# plt.plot(sparsity_levels, list(map(lambda x: x['map'], metrics_at_sparsity_levels.values())), label=\"map@10\", marker = \"o\")\n",
    "# plt.plot(sparsity_levels, list(map(lambda x: x['recall'], metrics_at_sparsity_levels.values())), label=\"recall@10\", marker = \"o\")\n",
    "# plt.plot(sparsity_levels, list(map(lambda x: x['precision'], metrics_at_sparsity_levels.values())), label=\"precision@10\", marker = \"o\")\n",
    "# plt.title(\"Metrics as function of Sparsity\")\n",
    "# plt.xlabel(\"Sparsity %\")\n",
    "# plt.legend()\n",
    "# plt.savefig(\"../results/metrics_over_sparsity.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sparsity_levels = list(map(lambda x: float(x), metrics_at_sparsity_levels))\n",
    "ndcg_mean = np.array(list(\n",
    "    map(lambda x: x['ndcgs'], metrics_at_sparsity_levels.values()))).mean(axis=1)\n",
    "ndcg_std = np.array(\n",
    "    list(map(lambda x: x['ndcgs'], metrics_at_sparsity_levels.values()))).std(axis=1)\n",
    "map_mean = np.array(\n",
    "    list(map(lambda x: x['map'], metrics_at_sparsity_levels.values()))).mean(axis=1)\n",
    "map_std = np.array(\n",
    "    list(map(lambda x: x['map'], metrics_at_sparsity_levels.values()))).std(axis=1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "trans1 = Affine2D().translate(-0.001, 0.0) + ax.transData\n",
    "trans2 = Affine2D().translate(0.001, 0.0) + ax.transData\n",
    "er1 = ax.errorbar(sparsity_levels, ndcg_mean, ndcg_std,\n",
    "                  linestyle='None', marker='o', label=\"ndcg\", transform=trans1)\n",
    "er2 = ax.errorbar(sparsity_levels, map_mean, map_std,\n",
    "                  linestyle='None', marker='o', label=\"map\", transform=trans2)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Sparsity\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4409406",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"../results/results_vae.json\", \"w\") as fp:\n",
    "    json.dump(metrics_at_sparsity_levels, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50aced5",
   "metadata": {
    "id": "Niu0b4U1PUwQ"
   },
   "source": [
    "# 6 References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967450da",
   "metadata": {
    "id": "A51MUkNVPSX0"
   },
   "source": [
    "[Liang, Dawen, et al, 2018] [Liang, Dawen, et al. \"Variational autoencoders for collaborative filtering.\" Proceedings of the 2018 World Wide Web Conference. 2018.](https://dl.acm.org/doi/pdf/10.1145/3178876.3186150?casa_token=zul5haircsAAAAAA:iIKn7y-xWwSeqaP-MmmyUaJoJuNZX9Fx1aXeFJwkwtMpVDCrPMW3kZjuYo1LKhSuMeUMNf1mbP2o)\n",
    "\n",
    "[Kingma et al, 2013] [Kingma, Diederik P., and Max Welling. \"Auto-encoding variational bayes.\"  (2013).](https://arxiv.org/pdf/1312.6114.pdf)\n",
    "\n",
    "[Burgess et al, 2018] [Burgess, Christopher P., et al. \"Understanding disentangling in $\\beta $-VAE.\" (2018)](https://arxiv.org/pdf/1804.03599.pdf)\n",
    "\n",
    "[Higgins et al, 2016] [Higgins, Irina, et al. \"beta-vae: Learning basic visual concepts with a constrained variational framework.\" (2016).](https://openreview.net/pdf?id=Sy2fzU9gl)\n",
    "\n",
    "\n",
    "[Bowman et al, 2015] [Samuel R. Bowman, Luke Vilnis, Oriol Vinyals, Andrew M. Dai, Rafal Jozefowicz,\n",
    "and Samy Bengio. 2015. Generating sentences from a continuous space. (2015).](https://arxiv.org/pdf/1511.06349.pdf)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
